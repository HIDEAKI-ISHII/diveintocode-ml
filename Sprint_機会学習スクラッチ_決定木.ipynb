{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルデータセット2の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決定木のスクラッチ（ScratchDecesionTreeClassifierDepth1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    深さ1の決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left_label = None\n",
    "        self.right_label = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        ig_max, feature_index, threshold = dt.get_max_ig(X, y)\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # 左の子ノードのラベルを取得\n",
    "        self.left_label = np.argmax(np.bincount(y[X[:, self.feature_index] >= self.threshold]))\n",
    "        \n",
    "        # 右の子ノードのラベルを取得\n",
    "        self.right_label = np.argmax(np.bincount(y[X[:, self.feature_index] < self.threshold]))        \n",
    "        \n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print(\"最大の情報利得： {}\".format(ig_max))\n",
    "            print(\"分割対象の特徴量のインデックス： {}\".format(feature_index))\n",
    "            print(\"閾値： {}\".format(threshold))\n",
    "            print(\"左の子ノードのラベル： {}\".format(self.left_label))\n",
    "            print(\"右の子ノードのラベル： {}\".format(self.right_label))            \n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量        \n",
    "        \n",
    "        Returns\n",
    "        y_pred : 次の形のndarray, shape (n_samples, )\n",
    "             推定値\n",
    "        \"\"\"\n",
    "        y_pred = np.where(X[:, self.feature_index] >= self.threshold, self.left_label, self.right_label)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def calc_gini(self, y):\n",
    "        \"\"\"\n",
    "        gini不純度を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "            \n",
    "        Returns\n",
    "        gini : float\n",
    "          ジニ不純度    \n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        score = 0\n",
    "        \n",
    "        # giniの算出\n",
    "        for cls in np.unique(y):\n",
    "            score  = score  + (len(y[y==cls]) / len(y)) ** 2\n",
    "            \n",
    "        gini = 1 - score\n",
    "\n",
    "        return gini\n",
    "    \n",
    "    \n",
    "    def calc_information_gain(self, X, y, index, threshold):\n",
    "        \"\"\"\n",
    "        情報利得を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        index : int\n",
    "            特徴量のインデックス         \n",
    "        index : float\n",
    "            閾値                \n",
    "            \n",
    "        Returns\n",
    "        ig : float\n",
    "          情報利得\n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        \n",
    "        # 親ノードのginiの算出\n",
    "        gini_parent = self.calc_gini(y)\n",
    "        \n",
    "        # 閾値以上のginiの算出（左の子ノード）\n",
    "        y_left = y[X[:, index] >= threshold] # 閾値以上の目的変数\n",
    "        gini_left = self.calc_gini(y_left)\n",
    "        \n",
    "        # 閾値未満のginiの算出（右の子ノード）\n",
    "        y_right = y[X[:, index] < threshold] # 閾値未満の目的変数\n",
    "        gini_right = self.calc_gini(y_right)\n",
    "        \n",
    "        ig = gini_parent  - gini_left * len(y_left) / len(y) - gini_right * len(y_right) / len(y) \n",
    "        \n",
    "        return ig\n",
    "    \n",
    "    \n",
    "    def get_max_ig(self, X, y):\n",
    "        \"\"\"\n",
    "        最大の情報利得を求める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "            \n",
    "        Returns\n",
    "        ig_max : float\n",
    "            最大の情報利得\n",
    "        feature_index : int\n",
    "            特徴量のインデックス           \n",
    "        threshold : float\n",
    "            閾値        \n",
    "        \"\"\"\n",
    "        ig_max = 0\n",
    "        feature_index = None\n",
    "        threshold = None\n",
    "        ig = None\n",
    "\n",
    "        for idx in range(X.shape[1]):\n",
    "            values = X[:, idx]\n",
    "            for val in values:\n",
    "                ig = self.calc_information_gain(X, y, idx, val)\n",
    "                if ig_max < ig:\n",
    "                    ig_max = ig\n",
    "                    threshold = val\n",
    "                    feature_index = idx   \n",
    "        \n",
    "        return ig_max, feature_index, threshold\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】不純度を求める関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $I(t) = 1-\\sum_{i=1}^{K}P^2(C_i|t) = 1-\\sum_{i=1}^{K}(\\frac{N_{t,i}}{N_{t,all}})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc_gini の実装\n",
    "```python \n",
    "def calc_gini(self, y):\n",
    "    \"\"\"\n",
    "    gini不純度を計算する\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "        訓練データの正解値\n",
    "\n",
    "    Returns\n",
    "    gini : float\n",
    "      ジニ不純度    \n",
    "    \"\"\"\n",
    "    gini = 0\n",
    "    score = 0\n",
    "\n",
    "    # giniの算出\n",
    "    for cls in np.unique(y):\n",
    "        score  = score  + (len(y[y==cls]) / len(y)) ** 2\n",
    "\n",
    "    gini = 1 - score\n",
    "\n",
    "    return gini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gini不純度を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "40\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# サンプルデータ\n",
    "print(y)\n",
    "print(len(y))\n",
    "print(len(y[y==0]))\n",
    "print(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $1-\\left( \\left( \\dfrac {20}{40}\\right) ^{2}+\\left( \\dfrac {20}{40}\\right) ^{2}\\right) =0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# gini不純度を計算\n",
    "dt = ScratchDecesionTreeClassifierDepth1()\n",
    "gini = dt.calc_gini(y)\n",
    "print(gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】情報利得を求める関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情報利得を求める関数の実装\n",
    "```python \n",
    "def calc_information_gain(self, X, y, index, threshold):\n",
    "    \"\"\"\n",
    "    情報利得を計算する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        訓練データの特徴量\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "        訓練データの正解値\n",
    "    index : int\n",
    "        特徴量のインデックス         \n",
    "    index : float\n",
    "        閾値                \n",
    "\n",
    "    Returns\n",
    "    ig : float\n",
    "      情報利得\n",
    "    \"\"\"\n",
    "    gini = 0\n",
    "\n",
    "    # 親ノードのginiの算出\n",
    "    gini_parent = self.calc_gini(y)\n",
    "\n",
    "    # 閾値以上のginiの算出（左の子ノード）\n",
    "    y_left = y[X[:, index] >= threshold] # 閾値以上の目的変数\n",
    "    gini_left = self.calc_gini(y_left)\n",
    "\n",
    "    # 閾値未満のginiの算出（右の子ノード）\n",
    "    y_right = y[X[:, index] < threshold] # 閾値未満の目的変数\n",
    "    gini_right = self.calc_gini(y_right)\n",
    "\n",
    "    ig = gini_parent  - gini_left * len(y_left) / len(y) - gini_right * len(y_right) / len(y) \n",
    "\n",
    "    return ig\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情報利得を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 0\n",
    "threshold = -0.65259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005050505050504944\n"
     ]
    }
   ],
   "source": [
    "# 情報利得を求める\n",
    "dt = ScratchDecesionTreeClassifierDepth1()\n",
    "gini = dt.calc_information_gain(X, y, feature_index, threshold)\n",
    "print(gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大の情報利得を求める関数の実装\n",
    "```python \n",
    "def get_max_ig(self, X, y):\n",
    "    \"\"\"\n",
    "    最大の情報利得を求める\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        訓練データの特徴量\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "        訓練データの正解値\n",
    "\n",
    "    Returns\n",
    "    ig_max : float\n",
    "        最大の情報利得\n",
    "    feature_index : int\n",
    "        特徴量のインデックス           \n",
    "    threshold : float\n",
    "        閾値        \n",
    "    \"\"\"\n",
    "    ig_max = 0\n",
    "    feature_index = None\n",
    "    threshold = None\n",
    "    ig = None\n",
    "\n",
    "    for idx in range(X.shape[1]):\n",
    "        values = X[:, idx]\n",
    "        for val in values:\n",
    "            ig = self.calc_information_gain(X, y, idx, val)\n",
    "            if ig_max < ig:\n",
    "                ig_max = ig\n",
    "                threshold = val\n",
    "                feature_index = idx   \n",
    "\n",
    "    return ig_max, feature_index, threshold\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit の実装\n",
    "```python \n",
    "def fit(self, X, y):\n",
    "    \"\"\"\n",
    "    決定木分類器を学習する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        訓練データの特徴量\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "        訓練データの正解値\n",
    "    \"\"\"\n",
    "\n",
    "    ig_max, feature_index, threshold = dt.get_max_ig(X, y)\n",
    "    self.feature_index = feature_index\n",
    "    self.threshold = threshold\n",
    "\n",
    "    # 左の子ノードのラベルを取得\n",
    "    self.left_label = np.argmax(np.bincount(y[X[:, self.feature_index] >= self.threshold]))\n",
    "\n",
    "    # 右の子ノードのラベルを取得\n",
    "    self.right_label = np.argmax(np.bincount(y[X[:, self.feature_index] < self.threshold]))        \n",
    "\n",
    "\n",
    "    if self.verbose:\n",
    "        #verboseをTrueにした際は学習過程を出力\n",
    "        print(\"最大の情報利得： {}\".format(ig_max))\n",
    "        print(\"分割対象の特徴量のインデックス： {}\".format(feature_index))\n",
    "        print(\"閾値： {}\".format(threshold))\n",
    "        print(\"左の子ノードのラベル： {}\".format(self.left_label))\n",
    "        print(\"右の子ノードのラベル： {}\".format(self.right_label))     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大の情報利得： 0.07680250783699061\n",
      "分割対象の特徴量のインデックス： 1\n",
      "閾値： 5.3524\n",
      "左の子ノードのラベル： 1\n",
      "右の子ノードのラベル： 0\n"
     ]
    }
   ],
   "source": [
    "dt = ScratchDecesionTreeClassifierDepth1(True)\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict の実装\n",
    "```python \n",
    "def predict(self, X):\n",
    "    \"\"\"\n",
    "    決定木分類器を使いラベルを推定する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        訓練データの特徴量        \n",
    "\n",
    "    Returns\n",
    "    y_pred : 次の形のndarray, shape (n_samples, )\n",
    "         推定値\n",
    "    \"\"\"\n",
    "    y_pred = np.where(X[:, self.feature_index] >= self.threshold, self.left_label, self.right_label)\n",
    "\n",
    "    return y_pred \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ① 今回のスクラッチを利用したとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　訓練データと検証データに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 0) # 訓練データ70%、検証データ30%として分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大の情報利得： 0.13494897959183677\n",
      "分割対象の特徴量のインデックス： 1\n",
      "閾値： 0.5927312019831511\n",
      "左の子ノードのラベル： 1\n",
      "右の子ノードのラベル： 0\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "dt = ScratchDecesionTreeClassifierDepth1(True)\n",
    "dt.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[1 1 1 0 0 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 推定（testデータ）\n",
    "y_val_pred = dt.predict(X_val_std)\n",
    "print(y_val_pred)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy（正解率）：　0.5\n",
      "\n",
      "Precision（適合率）：　0.5555555555555556\n",
      "\n",
      "Recall（再現率）：　0.5428571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy（正解率）：　{}\\n\".format(accuracy_score(y_val, y_val_pred)))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision（適合率）：　{}\\n\".format(precision_score(y_val, y_val_pred, average='macro')))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall（再現率）：　{}\\n\".format(recall_score(y_val, y_val_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ② scikit-learnによる実装のとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth=1) # 決定木のインスタンスを生成\n",
    "clf_tree.fit(X_train_std, y_train)\n",
    "y_pred_tree = clf_tree.predict(X_val_std) # 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy（正解率）：　0.5\n",
      "\n",
      "Precision（適合率）：　0.5555555555555556\n",
      "\n",
      "Recall（再現率）：　0.5428571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy（正解率）：　{}\\n\".format(accuracy_score(y_val, y_pred_tree)))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision（適合率）：　{}\\n\".format(precision_score(y_val, y_pred_tree, average='macro')))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall（再現率）：　{}\\n\".format(recall_score(y_val, y_pred_tree, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 「① 今回のスクラッチを利用したとき」と「② scikit-learnによる実装のとき」は検証結果が同じとなった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】決定領域の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# 決定領域を表示する関数\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_region(X_val_std, y_val, dt, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）深さ2の決定木分類器クラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注）【問題7】と【問題８】のクラスは同じ構造で実装してあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 深さ2の決定木分類器クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth2():\n",
    "    \"\"\"\n",
    "    深さに制限のない決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose, max_depth):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.tree = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # ルートノードの作成\n",
    "        self.tree = Node(self.verbose, self.max_depth)\n",
    "        # ルートノードの分割\n",
    "        self.tree.split_node(X, y, current_depth = 0)\n",
    "   \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量        \n",
    "        \n",
    "        Returns\n",
    "        y_pred : 次の形のndarray, shape (n_samples, )\n",
    "             推定値\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred = []\n",
    "        for Xi in X:\n",
    "            y_pred.append(self.tree.predict(Xi))\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② ノードクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, verbose, max_depth):\n",
    "        self.verbose = verbose                    # verboseをTrueにした際は学習過程を出力\n",
    "        self.max_depth = max_depth        # 最大の深さ\n",
    "        self.feature_idx = None                  # 分割対象の特徴量のインデックス\n",
    "        self.threshold = None                      # 閾値\n",
    "        self.left = None                                 # 左のノードオブジェクト\n",
    "        self.right = None                               # 右のノードオブジェクト\n",
    "        self.label = None                               # ノードのクラス\n",
    "        \n",
    "        \n",
    "    def split_node(self, X, y, current_depth):\n",
    "        \n",
    "        # ノードの「現在の深さ」が「最大の深さ」と等しい場合、または目的変数のクラスの種類が「１つ」の場合\n",
    "        if current_depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            self.label = np.argmax(np.bincount(y)) #最も多いクラスの値を取得\n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                print(\"現在の深さ： {}\".format(current_depth))\n",
    "                print(\"ラベルの値： {}\".format(self.label))            \n",
    "            return\n",
    "        \n",
    "        # 最大の情報利得になる値を取得\n",
    "        ig_max, feature_idx, threshold = self.get_max_ig(X, y)\n",
    "        \n",
    "        self.feature_idx = feature_idx         # 分割対象の特徴量のインデックス\n",
    "        self.threshold = threshold                # 閾値\n",
    "        \n",
    "        left_idx = np.where(X[:, self.feature_idx] < self.threshold)          # 閾値未満の特徴量のインデックスを取得\n",
    "        right_idx = np.where(X[:, self.feature_idx] >= self.threshold)     # 閾値以上の特徴量のインデックスを取得\n",
    "        \n",
    "        self.left = Node(self.verbose, self.max_depth)           # 左の子ノードのオブジェクトを作成\n",
    "        self.right = Node(self.verbose, self.max_depth)         # 右の子ノードのオブジェクトを作成\n",
    "        \n",
    "        self.left.split_node(X[left_idx], y[left_idx], current_depth + 1)           # 左の子ノードの「split_node」を呼び出し\n",
    "        self.right.split_node(X[right_idx], y[right_idx], current_depth + 1)    # 右の子ノードの「split_node」を呼び出し\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print(\"現在の深さ： {}\".format(current_depth))\n",
    "            print(\"最大の情報利得： {}\".format(ig_max))\n",
    "            print(\"分割対象の特徴量のインデックス： {}\".format(feature_index))\n",
    "            print(\"閾値： {}\".format(threshold))\n",
    "        \n",
    "        \n",
    "    def calc_gini(self, y):\n",
    "        \"\"\"\n",
    "        gini不純度を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "            \n",
    "        Returns\n",
    "        gini : float\n",
    "          ジニ不純度    \n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        score = 0\n",
    "        \n",
    "        # giniの算出\n",
    "        for cls in np.unique(y):\n",
    "            score  = score  + (len(y[y==cls]) / len(y)) ** 2\n",
    "        gini = 1 - score\n",
    "\n",
    "        return gini\n",
    "    \n",
    "    \n",
    "    def calc_information_gain(self, X, y, index, threshold):\n",
    "        \"\"\"\n",
    "        情報利得を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        index : int\n",
    "            特徴量のインデックス         \n",
    "        index : float\n",
    "            閾値                \n",
    "            \n",
    "        Returns\n",
    "        ig : float\n",
    "          情報利得\n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        \n",
    "        # 親ノードのginiの算出\n",
    "        gini_parent = self.calc_gini(y)\n",
    "        \n",
    "        # 閾値未満のginiの算出（左の子ノード）\n",
    "        y_left = y[X[:, index] < threshold] # 閾値未満の目的変数\n",
    "        gini_left = self.calc_gini(y_left)\n",
    "        \n",
    "        # 閾値以上のginiの算出（右の子ノード）\n",
    "        y_right = y[X[:, index] >= threshold] # 閾値以上の目的変数\n",
    "        gini_right = self.calc_gini(y_right)\n",
    "        \n",
    "        # 情報利得を計算\n",
    "        ig = gini_parent  - gini_left * len(y_left) / len(y) - gini_right * len(y_right) / len(y) \n",
    "        \n",
    "        return ig\n",
    "    \n",
    "    \n",
    "    def get_max_ig(self, X, y):\n",
    "        \"\"\"\n",
    "        最大の情報利得を求める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "            \n",
    "        Returns\n",
    "        ig_max : float\n",
    "            最大の情報利得\n",
    "        feature_index : int\n",
    "            特徴量のインデックス           \n",
    "        threshold : float\n",
    "            閾値        \n",
    "        \"\"\"\n",
    "        ig_max = 0\n",
    "        feature_index = None\n",
    "        threshold = None\n",
    "        ig = None\n",
    "        \n",
    "        # すべての特徴量の値について情報利得を計算する\n",
    "        for idx in range(X.shape[1]):\n",
    "            values = X[:, idx]\n",
    "            for val in values:\n",
    "                ig = self.calc_information_gain(X, y, idx, val)\n",
    "                if ig_max < ig:\n",
    "                    ig_max = ig\n",
    "                    threshold = val\n",
    "                    feature_index = idx   \n",
    "        \n",
    "        return ig_max, feature_index, threshold    \n",
    "    \n",
    "    def predict(self, Xi):\n",
    "        \"\"\"\n",
    "        最大の情報利得を求める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (1, n_features)\n",
    "            推定データの特徴量\n",
    "\n",
    "        Returns\n",
    "        label : object\n",
    "            ラベル \n",
    "        \"\"\"        \n",
    "        \n",
    "        # ラベルに値がある（子ノードがない）場合\n",
    "        if self.label is not None:\n",
    "            return self.label\n",
    "        \n",
    "        if Xi[self.feature_idx] < self.threshold:        #  閾値未満の場合\n",
    "            return self.left.predict(Xi)                         # 左の子ノードの「predict」を呼び出し\n",
    "        elif Xi[self.feature_idx] >= self.threshold:  #  閾値以上の場合\n",
    "            return self.right.predict(Xi)                       # 右の子ノードの「predict」を呼び出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 深さが「2」の学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在の深さ： 2\n",
      "ラベルの値： 0\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 1\n",
      "最大の情報利得： 0.051578947368421\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 1.2376627691639501\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 1\n",
      "最大の情報利得： 0.05208333333333334\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 1.2663521994222138\n",
      "現在の深さ： 0\n",
      "最大の情報利得： 0.13494897959183677\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 0.5927312019831511\n"
     ]
    }
   ],
   "source": [
    "# 学習（深さが4の場合）\n",
    "dt2 = ScratchDecesionTreeClassifierDepth2(verbose=True, max_depth=2)\n",
    "dt2.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_val_pred = dt2.predict(X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y2_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy（正解率）：　0.5\n",
      "\n",
      "Precision（適合率）：　0.5142857142857142\n",
      "\n",
      "Recall（再現率）：　0.5142857142857142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy（正解率）：　{}\\n\".format(accuracy_score(y_val, y2_val_pred)))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision（適合率）：　{}\\n\".format(precision_score(y_val, y2_val_pred, average='macro')))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall（再現率）：　{}\\n\".format(recall_score(y_val, y2_val_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】（アドバンス課題）深さに制限のない決定木分類器クラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 深さに制限のない決定木分類器クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepthInf():\n",
    "    \"\"\"\n",
    "    深さに制限のない決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose, max_depth):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.tree = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # ルートノードの作成\n",
    "        self.tree = Node(self.verbose, self.max_depth)\n",
    "        # ルートノードの分割\n",
    "        self.tree.split_node(X, y, current_depth = 0)\n",
    "   \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量        \n",
    "        \n",
    "        Returns\n",
    "        y_pred : 次の形のndarray, shape (n_samples, )\n",
    "             推定値\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred = []\n",
    "        for Xi in X:\n",
    "            y_pred.append(self.tree.predict(Xi))\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② ノードクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, verbose, max_depth):\n",
    "        self.verbose = verbose                    # verboseをTrueにした際は学習過程を出力\n",
    "        self.max_depth = max_depth        # 最大の深さ\n",
    "        self.feature_idx = None                  # 分割対象の特徴量のインデックス\n",
    "        self.threshold = None                      # 閾値\n",
    "        self.left = None                                 # 左のノードオブジェクト\n",
    "        self.right = None                               # 右のノードオブジェクト\n",
    "        self.label = None                               # ノードのクラス\n",
    "        \n",
    "        \n",
    "    def split_node(self, X, y, current_depth):\n",
    "        \n",
    "        # ノードの「現在の深さ」が「最大の深さ」と等しい場合、または目的変数のクラスの種類が「１つ」の場合\n",
    "        if current_depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            self.label = np.argmax(np.bincount(y)) #最も多いクラスの値を取得\n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                print(\"現在の深さ： {}\".format(current_depth))\n",
    "                print(\"ラベルの値： {}\".format(self.label))                     \n",
    "            return\n",
    "        \n",
    "        # 最大の情報利得になる値を取得\n",
    "        ig_max, feature_idx, threshold = self.get_max_ig(X, y)\n",
    "        \n",
    "        self.feature_idx = feature_idx         # 分割対象の特徴量のインデックス\n",
    "        self.threshold = threshold                # 閾値\n",
    "        \n",
    "        left_idx = np.where(X[:, self.feature_idx] < self.threshold)          # 閾値未満の特徴量のインデックスを取得\n",
    "        right_idx = np.where(X[:, self.feature_idx] >= self.threshold)     # 閾値以上の特徴量のインデックスを取得\n",
    "        \n",
    "        self.left = Node(self.verbose, self.max_depth)           # 左の子ノードのオブジェクトを作成\n",
    "        self.right = Node(self.verbose, self.max_depth)         # 右の子ノードのオブジェクトを作成\n",
    "        \n",
    "        self.left.split_node(X[left_idx], y[left_idx], current_depth + 1)           # 左の子ノードの「split_node」を呼び出し\n",
    "        self.right.split_node(X[right_idx], y[right_idx], current_depth + 1)    # 右の子ノードの「split_node」を呼び出し\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print(\"現在の深さ： {}\".format(current_depth))\n",
    "            print(\"最大の情報利得： {}\".format(ig_max))\n",
    "            print(\"分割対象の特徴量のインデックス： {}\".format(feature_index))\n",
    "            print(\"閾値： {}\".format(threshold)) \n",
    "        \n",
    "        \n",
    "    def calc_gini(self, y):\n",
    "        \"\"\"\n",
    "        gini不純度を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "            \n",
    "        Returns\n",
    "        gini : float\n",
    "          ジニ不純度    \n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        score = 0\n",
    "        \n",
    "        # giniの算出\n",
    "        for cls in np.unique(y):\n",
    "            score  = score  + (len(y[y==cls]) / len(y)) ** 2\n",
    "        gini = 1 - score\n",
    "\n",
    "        return gini\n",
    "    \n",
    "    \n",
    "    def calc_information_gain(self, X, y, index, threshold):\n",
    "        \"\"\"\n",
    "        情報利得を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        index : int\n",
    "            特徴量のインデックス         \n",
    "        index : float\n",
    "            閾値                \n",
    "            \n",
    "        Returns\n",
    "        ig : float\n",
    "          情報利得\n",
    "        \"\"\"\n",
    "        gini = 0\n",
    "        \n",
    "        # 親ノードのginiの算出\n",
    "        gini_parent = self.calc_gini(y)\n",
    "        \n",
    "        # 閾値未満のginiの算出（左の子ノード）\n",
    "        y_left = y[X[:, index] < threshold] # 閾値未満の目的変数\n",
    "        gini_left = self.calc_gini(y_left)\n",
    "        \n",
    "        # 閾値以上のginiの算出（右の子ノード）\n",
    "        y_right = y[X[:, index] >= threshold] # 閾値以上の目的変数\n",
    "        gini_right = self.calc_gini(y_right)\n",
    "        \n",
    "        # 情報利得を計算\n",
    "        ig = gini_parent  - gini_left * len(y_left) / len(y) - gini_right * len(y_right) / len(y) \n",
    "        \n",
    "        return ig\n",
    "    \n",
    "    \n",
    "    def get_max_ig(self, X, y):\n",
    "        \"\"\"\n",
    "        最大の情報利得を求める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "            \n",
    "        Returns\n",
    "        ig_max : float\n",
    "            最大の情報利得\n",
    "        feature_index : int\n",
    "            特徴量のインデックス           \n",
    "        threshold : float\n",
    "            閾値        \n",
    "        \"\"\"\n",
    "        ig_max = 0\n",
    "        feature_index = None\n",
    "        threshold = None\n",
    "        ig = None\n",
    "        \n",
    "        # すべての特徴量の値について情報利得を計算する\n",
    "        for idx in range(X.shape[1]):\n",
    "            values = X[:, idx]\n",
    "            for val in values:\n",
    "                ig = self.calc_information_gain(X, y, idx, val)\n",
    "                if ig_max < ig:\n",
    "                    ig_max = ig\n",
    "                    threshold = val\n",
    "                    feature_index = idx   \n",
    "        \n",
    "        return ig_max, feature_index, threshold    \n",
    "    \n",
    "    def predict(self, Xi):\n",
    "        \"\"\"\n",
    "        最大の情報利得を求める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (1, n_features)\n",
    "            推定データの特徴量\n",
    "\n",
    "        Returns\n",
    "        label : object\n",
    "            ラベル \n",
    "        \"\"\"        \n",
    "        \n",
    "        # ラベルに値がある（子ノードがない）場合\n",
    "        if self.label is not None:\n",
    "            return self.label\n",
    "        \n",
    "        if Xi[self.feature_idx] < self.threshold:        #  閾値未満の場合\n",
    "            return self.left.predict(Xi)                         # 左の子ノードの「predict」を呼び出し\n",
    "        elif Xi[self.feature_idx] >= self.threshold:  #  閾値以上の場合\n",
    "            return self.right.predict(Xi)                       # 右の子ノードの「predict」を呼び出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 深さが「3」の学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在の深さ： 3\n",
      "ラベルの値： 1\n",
      "現在の深さ： 3\n",
      "ラベルの値： 0\n",
      "現在の深さ： 2\n",
      "最大の情報利得： 0.0603262542320715\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： -1.5889245634111966\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 1\n",
      "最大の情報利得： 0.051578947368421\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 1.2376627691639501\n",
      "現在の深さ： 3\n",
      "ラベルの値： 0\n",
      "現在の深さ： 3\n",
      "ラベルの値： 1\n",
      "現在の深さ： 2\n",
      "最大の情報利得： 0.4444444444444444\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 0.6572504015972741\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 1\n",
      "最大の情報利得： 0.05208333333333334\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 1.2663521994222138\n",
      "現在の深さ： 0\n",
      "最大の情報利得： 0.13494897959183677\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 0.5927312019831511\n"
     ]
    }
   ],
   "source": [
    "# 学習（深さが３の場合）\n",
    "dt3 = ScratchDecesionTreeClassifierDepthInf(verbose=True, max_depth=3)\n",
    "dt3.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_val_pred = dt3.predict(X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y3_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy（正解率）：　0.5833333333333334\n",
      "\n",
      "Precision（適合率）：　0.625\n",
      "\n",
      "Recall（再現率）：　0.6142857142857143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy（正解率）：　{}\\n\".format(accuracy_score(y_val, y3_val_pred)))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision（適合率）：　{}\\n\".format(precision_score(y_val, y3_val_pred, average='macro')))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall（再現率）：　{}\\n\".format(recall_score(y_val, y3_val_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② 深さが「無限」の学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現在の深さ： 3\n",
      "ラベルの値： 1\n",
      "現在の深さ： 7\n",
      "ラベルの値： 0\n",
      "現在の深さ： 7\n",
      "ラベルの値： 1\n",
      "現在の深さ： 6\n",
      "最大の情報利得： 0.48\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： -1.026653407481607\n",
      "現在の深さ： 6\n",
      "ラベルの値： 0\n",
      "現在の深さ： 5\n",
      "最大の情報利得： 0.07999999999999985\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： -0.1634240497422507\n",
      "現在の深さ： 5\n",
      "ラベルの値： 1\n",
      "現在の深さ： 4\n",
      "最大の情報利得： 0.17777777777777787\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 0.815791963159757\n",
      "現在の深さ： 4\n",
      "ラベルの値： 0\n",
      "現在の深さ： 3\n",
      "最大の情報利得： 0.04938271604938271\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： -0.3630501753701628\n",
      "現在の深さ： 2\n",
      "最大の情報利得： 0.0603262542320715\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： -1.5889245634111966\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 1\n",
      "最大の情報利得： 0.051578947368421\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 1.2376627691639501\n",
      "現在の深さ： 3\n",
      "ラベルの値： 0\n",
      "現在の深さ： 3\n",
      "ラベルの値： 1\n",
      "現在の深さ： 2\n",
      "最大の情報利得： 0.4444444444444444\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 0.6572504015972741\n",
      "現在の深さ： 2\n",
      "ラベルの値： 1\n",
      "現在の深さ： 1\n",
      "最大の情報利得： 0.05208333333333334\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 1.2663521994222138\n",
      "現在の深さ： 0\n",
      "最大の情報利得： 0.13494897959183677\n",
      "分割対象の特徴量のインデックス： 0\n",
      "閾値： 0.5927312019831511\n"
     ]
    }
   ],
   "source": [
    "# 学習（深さが無限の場合）\n",
    "dt_inf = ScratchDecesionTreeClassifierDepthInf(verbose=True, max_depth=None)\n",
    "dt_inf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## → 深さを無限にしたとき、このデータでは最大の深さが「６」でノード分割が終了した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_inf_val_pred = dt_inf.predict(X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_inf_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy（正解率）：　0.8333333333333334\n",
      "\n",
      "Precision（適合率）：　0.8285714285714285\n",
      "\n",
      "Recall（再現率）：　0.8285714285714285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy（正解率）：　{}\\n\".format(accuracy_score(y_val, y_inf_val_pred)))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision（適合率）：　{}\\n\".format(precision_score(y_val, y_inf_val_pred, average='macro')))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall（再現率）：　{}\\n\".format(recall_score(y_val, y_inf_val_pred, average='macro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "### Sprintの目的\n",
    "フレームワークのコードを読めるようにする  \n",
    "フレームワークを習得し続けられるようになる  \n",
    "理論を知っている範囲をフレームワークで動かす  \n",
    "### どのように学ぶか\n",
    "前半はTensorFlowのExampleを動かします。後半ではKerasのコードを書いていきます。  \n",
    "## 2.公式Example\n",
    "深層学習フレームワークには公式に様々なモデルのExampleコードが公開されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】公式チュートリアルモデルを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。  \n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### → 「画像：画像のセグメンテーション」を講義内で発表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】（アドバンス課題）様々な手法を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。  \n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。  \n",
    "models/research at master · tensorflow/models  \n",
    "google-research/google-research: Google AI Research  \n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.異なるフレームワークへの書き換え\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。  \n",
    "Iris（Iris-versicolorとIris-virginicaのみの2値分類）  \n",
    "Iris（3種類全ての目的変数を使用して多値分類）  \n",
    "House Prices  \n",
    "MNIST  \n",
    "### Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。  \n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chidori/.pyenv/versions/anaconda3-5.3.1/envs/tensortest/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/chidori/.pyenv/versions/anaconda3-5.3.1/envs/tensortest/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 64 samples\n",
      "Epoch 1/20\n",
      "64/64 [==============================] - 0s 7ms/sample - loss: 0.8749 - acc: 0.5469\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.7045 - acc: 0.5312\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6725 - acc: 0.5000\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.7008 - acc: 0.4688\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6949 - acc: 0.4844\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6969 - acc: 0.5312\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6927 - acc: 0.5312\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6939 - acc: 0.5312\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6924 - acc: 0.5312\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6943 - acc: 0.5312\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6933 - acc: 0.5312\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6932 - acc: 0.5312\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6943 - acc: 0.5312\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6938 - acc: 0.5312\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6942 - acc: 0.5312\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6955 - acc: 0.5312\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6936 - acc: 0.5312\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6934 - acc: 0.5312\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6930 - acc: 0.5312\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6925 - acc: 0.5312\n",
      "y_pred_proba [0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709 0.5343709\n",
      " 0.5343709]\n",
      "y_pred [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# セッションをクリアする\n",
    "K.clear_session()\n",
    "\n",
    "# モデルの初期化\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# レイヤーの追加\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation = tf.nn.relu, input_shape=(n_input,)))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation = tf.nn.sigmoid))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# 推定\n",
    "y_pred_proba = model.predict(X_train)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用可能な損失関数  \n",
    "https://keras.io/ja/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 1s 6ms/sample - loss: 0.3700 - acc: 0.8229\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.3133 - acc: 0.8681\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1398 - acc: 0.9514\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1183 - acc: 0.9583\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1536 - acc: 0.9375\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.2445 - acc: 0.8681\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1389 - acc: 0.9583\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0589 - acc: 0.9861\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1672 - acc: 0.9583\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1641 - acc: 0.9583\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0957 - acc: 0.9444\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.2957 - acc: 0.8819\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1486 - acc: 0.9514\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0973 - acc: 0.9653\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1098 - acc: 0.9583\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0409 - acc: 0.9861\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1932 - acc: 0.9097\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1687 - acc: 0.9444\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1333 - acc: 0.9583\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0589 - acc: 0.9722\n",
      "y_pred_proba [[1.4185780e-03 9.3347901e-01 6.5102495e-02]\n",
      " [9.9976677e-01 2.3320899e-04 4.5307058e-10]\n",
      " [1.1274481e-09 5.5794755e-04 9.9944204e-01]\n",
      " [9.9999607e-01 3.9029333e-06 5.4852373e-12]\n",
      " [3.2807048e-07 6.8415487e-03 9.9315816e-01]\n",
      " [3.4978024e-07 9.9412706e-03 9.9005836e-01]\n",
      " [1.4181013e-03 8.4020418e-01 1.5837772e-01]\n",
      " [1.0000000e+00 9.7753556e-09 1.6974857e-15]\n",
      " [2.4304205e-08 2.1573959e-03 9.9784255e-01]\n",
      " [9.9978966e-01 2.1033661e-04 1.1785223e-09]\n",
      " [3.4287052e-07 8.5867811e-03 9.9141288e-01]\n",
      " [9.2251173e-10 4.7520842e-04 9.9952483e-01]\n",
      " [9.9999988e-01 1.1460161e-07 2.6721718e-14]\n",
      " [9.9999988e-01 7.1938608e-08 2.5992316e-14]\n",
      " [3.7875232e-09 9.3775411e-04 9.9906224e-01]\n",
      " [1.0950053e-10 2.0482829e-04 9.9979514e-01]\n",
      " [9.9999654e-01 3.5113537e-06 4.3876174e-12]\n",
      " [2.4693895e-12 3.1812564e-05 9.9996817e-01]\n",
      " [1.0000000e+00 2.1513526e-10 9.7897529e-18]\n",
      " [9.9999881e-01 1.2029429e-06 1.4990037e-12]\n",
      " [2.7906035e-08 2.3987552e-03 9.9760121e-01]\n",
      " [1.7839584e-07 5.9938761e-03 9.9400592e-01]\n",
      " [1.6898452e-04 9.9840087e-01 1.4301602e-03]\n",
      " [9.9999952e-01 4.5959604e-07 3.7796966e-13]\n",
      " [4.1460679e-09 9.7217388e-04 9.9902785e-01]\n",
      " [9.9999905e-01 8.9673517e-07 3.7512682e-13]\n",
      " [1.5138867e-09 6.0568034e-04 9.9939430e-01]\n",
      " [8.0427184e-04 9.8580617e-01 1.3389519e-02]\n",
      " [1.4504526e-08 2.4116782e-03 9.9758828e-01]\n",
      " [3.4653047e-05 7.7547193e-02 9.2241818e-01]\n",
      " [4.7037735e-10 3.6451605e-04 9.9963546e-01]\n",
      " [9.9999964e-01 3.5816703e-07 1.6940584e-13]\n",
      " [1.1382925e-03 9.7526860e-01 2.3593089e-02]\n",
      " [6.9254313e-10 4.1209272e-04 9.9958795e-01]\n",
      " [1.9573229e-03 9.5482695e-01 4.3215815e-02]\n",
      " [2.7907740e-10 2.7565466e-04 9.9972433e-01]\n",
      " [9.9999964e-01 3.4501099e-07 2.9349415e-13]\n",
      " [1.7341005e-08 1.9647775e-03 9.9803525e-01]\n",
      " [1.0000000e+00 3.2817198e-08 7.9765931e-15]\n",
      " [7.6549593e-04 3.8779506e-01 6.1143947e-01]\n",
      " [1.4878284e-09 6.5919833e-04 9.9934083e-01]\n",
      " [9.7011839e-04 9.1194195e-01 8.7087944e-02]\n",
      " [9.9999869e-01 1.2776534e-06 7.7231440e-13]\n",
      " [5.7174173e-08 3.7498837e-03 9.9625009e-01]\n",
      " [5.9632934e-04 9.9166602e-01 7.7376920e-03]\n",
      " [6.8908982e-04 9.7168857e-01 2.7622292e-02]\n",
      " [6.4032457e-10 4.0767723e-04 9.9959236e-01]\n",
      " [1.0611434e-03 5.3783697e-01 4.6110189e-01]\n",
      " [1.3299707e-03 9.7562218e-01 2.3047850e-02]\n",
      " [9.9999571e-01 4.3458745e-06 6.1721331e-12]\n",
      " [4.3565815e-04 3.1199378e-01 6.8757057e-01]\n",
      " [9.9999988e-01 8.0159701e-08 2.6862246e-14]\n",
      " [9.9999988e-01 1.7606040e-07 6.7950819e-14]\n",
      " [2.8169854e-06 2.3481725e-02 9.7651553e-01]\n",
      " [2.4304205e-08 2.1573959e-03 9.9784255e-01]\n",
      " [3.7354755e-09 9.4846945e-04 9.9905151e-01]\n",
      " [1.0000000e+00 2.3813007e-08 5.0393022e-15]\n",
      " [7.1830861e-04 9.9296087e-01 6.3208523e-03]\n",
      " [3.4191712e-09 9.3966810e-04 9.9906033e-01]\n",
      " [3.2260274e-08 2.7365487e-03 9.9726343e-01]\n",
      " [7.5021549e-06 3.5732117e-02 9.6426046e-01]\n",
      " [8.8247570e-04 9.7669107e-01 2.2426525e-02]\n",
      " [1.9861981e-08 2.1506534e-03 9.9784935e-01]\n",
      " [5.6996102e-10 4.7218378e-04 9.9952781e-01]\n",
      " [9.3663885e-04 9.5158941e-01 4.7473993e-02]\n",
      " [9.9999964e-01 3.3407255e-07 1.6363663e-13]\n",
      " [9.9999988e-01 8.6067068e-08 3.9072410e-14]\n",
      " [1.1421699e-03 9.7923100e-01 1.9626813e-02]\n",
      " [4.4184635e-04 3.5419652e-01 6.4536166e-01]\n",
      " [5.2683125e-04 3.1674859e-01 6.8272454e-01]\n",
      " [9.9999988e-01 8.0103149e-08 2.9247424e-14]\n",
      " [3.3913832e-06 2.6422311e-02 9.7357428e-01]\n",
      " [1.9252946e-08 2.5008328e-03 9.9749917e-01]\n",
      " [9.9979347e-01 2.0652068e-04 3.8567943e-10]\n",
      " [5.8510277e-04 9.9247277e-01 6.9421274e-03]\n",
      " [1.3979940e-07 5.3631295e-03 9.9463671e-01]\n",
      " [9.9999976e-01 2.2522178e-07 1.1292270e-13]\n",
      " [9.9999976e-01 2.0195969e-07 2.0095620e-13]\n",
      " [1.2631295e-08 1.8105935e-03 9.9818939e-01]\n",
      " [9.9999881e-01 1.2026803e-06 1.0923710e-12]\n",
      " [8.9427372e-09 1.4781472e-03 9.9852186e-01]\n",
      " [4.7812176e-10 3.5544758e-04 9.9964452e-01]\n",
      " [1.0000000e+00 1.6844960e-09 1.9464801e-16]\n",
      " [9.9999714e-01 2.8326749e-06 4.7553190e-12]\n",
      " [7.1262382e-04 9.8044765e-01 1.8839780e-02]\n",
      " [5.4608466e-04 4.1629943e-01 5.8315450e-01]\n",
      " [2.2079251e-10 2.7725799e-04 9.9972278e-01]\n",
      " [9.9999809e-01 1.8556578e-06 1.1285064e-12]\n",
      " [1.2746174e-03 9.6216530e-01 3.6560081e-02]\n",
      " [6.1014721e-06 3.5643097e-02 9.6435082e-01]\n",
      " [9.9999964e-01 3.3284249e-07 2.5392633e-13]\n",
      " [9.9999988e-01 6.4606496e-08 2.3099620e-14]\n",
      " [8.0757294e-09 1.2288695e-03 9.9877113e-01]\n",
      " [5.1603222e-04 9.9255377e-01 6.9302316e-03]\n",
      " [3.0099557e-04 9.9749571e-01 2.2032284e-03]\n",
      " [4.3120759e-04 4.4273812e-01 5.5683070e-01]]\n",
      "y_pred [[0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# セッションをクリアする\n",
    "K.clear_session()\n",
    "\n",
    "# モデルの初期化\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# レイヤーの追加\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation = tf.nn.relu, input_shape=(n_input,)))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation = tf.nn.softmax))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# 推定\n",
    "y_pred_proba = model.predict(X_train)\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# データフレームから条件抽出\n",
    "X = np.array(df[['GrLivArea','YearBuilt']])\n",
    "y = np.array(df['SalePrice'])\n",
    "\n",
    "## 正則化\n",
    "ss = StandardScaler()\n",
    "ss.fit(X)\n",
    "X = ss.transform(X)\n",
    "\n",
    "y = np.log(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "## データの変形\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ハイパーパラメータ\n",
    "learning_rate = 0.005\n",
    "batch_size = 200\n",
    "num_epochs = 30\n",
    "n_hidden1 = 100\n",
    "n_hidden2 = 50\n",
    "n_samples = X_train.shape[0]\n",
    "n_input = X_train.shape[1]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 線形回帰のKerasによる表現\n",
    "単純パーセプトロンから活性化関数とバイアス項を取り除くと、単なる線形回帰問題になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples\n",
      "Epoch 1/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 2.7552\n",
      "Epoch 2/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.3763\n",
      "Epoch 3/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.3710\n",
      "Epoch 4/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.2078\n",
      "Epoch 5/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.3144\n",
      "Epoch 6/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.3828\n",
      "Epoch 7/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.2342\n",
      "Epoch 8/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1879\n",
      "Epoch 9/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1661\n",
      "Epoch 10/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.2781\n",
      "Epoch 11/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1475\n",
      "Epoch 12/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1398\n",
      "Epoch 13/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1386\n",
      "Epoch 14/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1651\n",
      "Epoch 15/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1282\n",
      "Epoch 16/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1183\n",
      "Epoch 17/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1334\n",
      "Epoch 18/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1479\n",
      "Epoch 19/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1149\n",
      "Epoch 20/20\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 0.1007\n",
      "mse: \n",
      " 0.10071241081290305\n",
      "paramater: \n",
      " [[-1.62442043e-01 -4.30753753e-02 -5.10630198e-02 -2.12931950e-02\n",
      "  -3.57933119e-02 -8.61941352e-02 -2.68171161e-01 -1.48282414e-02\n",
      "  -9.94841754e-02 -4.71083149e-02 -2.32892826e-01 -1.26573503e-01\n",
      "  -3.15968655e-02 -1.38776973e-01 -4.15726863e-02 -1.43072382e-01\n",
      "  -1.32190678e-02 -6.91405088e-02  6.42766729e-02 -2.43798662e-02\n",
      "  -5.82549125e-02 -8.44347924e-02 -2.45243870e-02 -8.65066517e-03\n",
      "  -1.98852532e-02 -7.67238066e-02 -3.89961600e-02 -3.47416848e-02\n",
      "  -1.18532926e-01 -1.46936074e-01 -2.27366462e-02 -4.85736616e-02\n",
      "  -2.64464039e-02 -9.29921940e-02 -5.74768074e-02 -5.56547679e-02\n",
      "  -5.51155023e-02 -2.96326037e-02 -1.17055707e-01 -2.80458629e-01\n",
      "  -2.85868406e-01 -5.50137013e-02 -3.33901823e-01 -5.55074885e-02\n",
      "  -2.18794029e-02 -3.43215577e-02 -5.46928719e-02 -2.83023790e-02\n",
      "   6.93845679e-04 -6.89040273e-02  1.07871159e-03 -9.15538073e-02\n",
      "   3.53308506e-02 -9.39757749e-02 -4.87909093e-02 -5.62520139e-03\n",
      "  -1.25146493e-01 -4.55871299e-02 -5.32833450e-02 -2.53401808e-02\n",
      "  -1.41664207e-01  1.43790588e-01 -8.27963501e-02  2.03188989e-04\n",
      "  -3.44565883e-02 -7.07238168e-02 -1.37855664e-01  3.95985832e-03\n",
      "  -1.05442967e-04 -7.79337063e-02 -1.18637376e-01  1.20880955e-03\n",
      "  -3.20529081e-02 -1.01546198e-01 -1.59209557e-02 -1.98515147e-01\n",
      "  -1.06744943e-02 -3.17139376e-04 -1.30639955e-01 -1.20449141e-02\n",
      "   8.40266468e-04 -7.62052611e-02 -5.32934181e-02 -1.07898012e-01\n",
      "  -5.01673877e-01 -1.59751862e-01  3.86703759e-02 -4.03885990e-02\n",
      "   1.70522910e-02 -1.10733565e-02 -1.39709841e-02 -9.68893804e-03\n",
      "  -1.00990407e-01  1.63700953e-01 -5.18709272e-02 -1.35080144e-01\n",
      "  -4.74330224e-02 -1.71883474e-03 -4.51223589e-02 -2.79072654e-02]\n",
      " [ 1.17466003e-01 -6.32369705e-03  3.52398679e-03 -1.09284669e-02\n",
      "   1.90226108e-01  5.19308820e-02  2.22633705e-02  2.86026374e-02\n",
      "   5.01137674e-02 -3.05774231e-02  1.00860238e-01 -6.96235001e-02\n",
      "   3.09499521e-02  1.81342140e-01  2.09921133e-02  1.06995732e-01\n",
      "   5.43152262e-03  1.18593648e-02 -4.96506728e-02  1.96000159e-01\n",
      "   1.08282067e-01 -1.24910856e-02  7.61351138e-02  1.80513673e-02\n",
      "   1.49920480e-02  6.17198609e-02 -3.26272286e-02  5.91249578e-02\n",
      "   1.62799388e-01  1.30296558e-01  3.28570954e-03 -1.49065233e-03\n",
      "   8.88489839e-03  7.34092435e-03  9.76548344e-02  3.59142348e-02\n",
      "   2.99604405e-02  4.27155867e-02  2.05352277e-01  1.35328203e-01\n",
      "  -1.12721004e-01  3.56681645e-02 -6.19311891e-02  5.89470789e-02\n",
      "  -6.60317950e-03  1.95365593e-01 -1.82268545e-02 -5.91274649e-02\n",
      "  -2.99100485e-02  1.11179262e-01 -1.22418158e-01  7.79955089e-02\n",
      "  -1.12669051e-01  7.13700950e-02  1.56218514e-01  7.14691058e-02\n",
      "   9.42652449e-02  3.06892861e-02  4.00332548e-02 -1.87007450e-02\n",
      "   1.94768626e-02 -8.55598319e-03  1.20979235e-01 -4.18370888e-02\n",
      "   1.21685378e-02  1.95247442e-01  6.57456145e-02  1.08705543e-03\n",
      "   3.65779884e-02  6.82920218e-02  8.78920853e-02 -4.74380236e-03\n",
      "   2.95243263e-02  1.44796297e-01  1.80987213e-02 -3.86309139e-02\n",
      "  -2.87019759e-02 -3.18332495e-05  1.45272046e-01 -5.62008237e-03\n",
      "  -1.59409884e-02  3.70501056e-02  4.03107516e-02  1.29496977e-01\n",
      "   1.26657054e-01  9.51526314e-02 -2.52608284e-02  1.28361741e-02\n",
      "  -1.72641629e-03  1.31373946e-02  2.37434562e-02 -1.66231450e-02\n",
      "   1.17589630e-01 -5.48315458e-02  3.32369879e-02  5.70821390e-02\n",
      "   1.37260959e-01 -1.52880384e-04  1.86911121e-01 -3.32858339e-02]]\n"
     ]
    }
   ],
   "source": [
    "# セッションをクリアする\n",
    "K.clear_session()\n",
    "\n",
    "# モデルの初期化\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# レイヤーの追加\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation = tf.nn.relu, input_shape=(n_input,)))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, use_bias=False))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.01), loss='mse')\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# 推定\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "mses = history.history['loss']\n",
    "param = model.get_weights()[0]\n",
    "print(\"mse: \\n\", mses[-1])\n",
    "print(\"paramater: \\n\", param)\n",
    "#print(\"y_pred: \\n\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 0から1のfloat型に変換\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 訓練データと検証データに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# one-hot表現 に変換\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "num_epochs = 5\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 12s 256us/sample - loss: 0.0586 - acc: 0.9818\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 12s 252us/sample - loss: 0.0387 - acc: 0.9886\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 12s 255us/sample - loss: 0.0343 - acc: 0.9906\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 14s 284us/sample - loss: 0.0331 - acc: 0.9912\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 16s 324us/sample - loss: 0.0302 - acc: 0.9924\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 16s 325us/sample - loss: 0.0286 - acc: 0.9929\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0281 - acc: 0.9930\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 15s 302us/sample - loss: 0.0259 - acc: 0.9936\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0267 - acc: 0.9937\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 15s 317us/sample - loss: 0.0270 - acc: 0.9938\n",
      "y_pred_proba [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.78547211e-38 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  2.06743091e-38 0.00000000e+00]\n",
      " [1.47329046e-35 1.03135347e-31 9.04601245e-30 6.27174358e-33\n",
      "  1.63232720e-20 1.53379351e-26 1.00000000e+00 0.00000000e+00\n",
      "  9.47110977e-21 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 4.28566979e-37 0.00000000e+00\n",
      "  5.06190723e-28 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.05860423e-20 6.25992839e-20 1.00000000e+00\n",
      "  0.00000000e+00 1.60005003e-24 0.00000000e+00 1.02255205e-21\n",
      "  2.55247794e-16 0.00000000e+00]\n",
      " [1.87773335e-08 6.29791685e-08 1.22088995e-05 1.38655232e-05\n",
      "  1.06195330e-11 2.20253787e-10 0.00000000e+00 9.99814689e-01\n",
      "  5.23707681e-15 1.59138523e-04]\n",
      " [1.06750992e-17 6.77272257e-13 2.65567213e-25 5.56966195e-10\n",
      "  6.12102610e-07 2.11244024e-15 0.00000000e+00 6.44729736e-09\n",
      "  2.16241631e-07 9.99999166e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.13635953e-35]\n",
      " [3.98494012e-06 1.04043232e-02 1.90038338e-01 5.62004507e-01\n",
      "  2.07708563e-05 1.84889399e-02 1.95234373e-18 8.54271185e-03\n",
      "  2.07633197e-01 2.86323903e-03]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.50241563e-22 1.89262476e-26 1.00000000e+00 6.36160114e-24\n",
      "  2.93599859e-18 5.15564628e-27 4.91996895e-18 5.29768174e-10\n",
      "  5.25143934e-27 3.67058514e-36]]\n",
      "y_pred [[0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# セッションをクリアする\n",
    "K.clear_session()\n",
    "\n",
    "# モデルの初期化\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# レイヤーの追加\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation = tf.nn.relu, input_shape=(n_input,)))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation = tf.nn.softmax))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=20,\n",
    "                    epochs=10,\n",
    "                    verbose=1)\n",
    "\n",
    "# 推定\n",
    "y_pred_proba = model.predict(X_train)\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "print(\"y_pred_proba\", y_pred_proba[:10])\n",
    "print(\"y_pred\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）PyTorchへの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① Iris（2値分類）をPyTorchで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.from_numpy(X_train).float(), requires_grad=True)\n",
    "y = Variable(torch.from_numpy(y_train).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "        self.fc2 = nn.Linear(10, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "outputs = net(Variable(torch.from_numpy(X_test).float()))\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "y_predicted = predicted.numpy()\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "accuracy = (int)(100 * np.sum(y_predicted == y_true) / len(y_predicted))\n",
    "print('accuracy: {0}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② Iris（多値分類）をPyTorchで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.from_numpy(X_train).float(), requires_grad=True)\n",
    "y = Variable(torch.from_numpy(y_train_one_hot).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "        self.fc2 = nn.Linear(10, 8)\n",
    "        self.fc3 = nn.Linear(8, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "outputs = net(Variable(torch.from_numpy(X_test).float()))\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "y_predicted = predicted.numpy()\n",
    "y_true = np.argmax(y_test_one_hot, axis=1)\n",
    "accuracy = (int)(100 * np.sum(y_predicted == y_true) / len(y_predicted))\n",
    "print('accuracy: {0}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ③ House PricesをPyTorchで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# データフレームから条件抽出\n",
    "X = np.array(df[['GrLivArea','YearBuilt']])\n",
    "y = np.array(df['SalePrice'])\n",
    "\n",
    "## 正則化\n",
    "ss = StandardScaler()\n",
    "ss.fit(X)\n",
    "X = ss.transform(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "## データの変形\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.from_numpy(X_train).float(), requires_grad=True)\n",
    "y = Variable(torch.from_numpy(y_train).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.5824, -0.5758]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# モデルの生成\n",
    "net = nn.Linear(in_features=2, out_features=1, bias=False)\n",
    "\n",
    "# オプティマイザの生成\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# 損失関数の生成\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# 学習前のパラメータ\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[52250.2539, 25747.5195]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoc in range(300):\n",
    "   # 前回のbackwardで計算した勾配の削除\n",
    "   optimizer.zero_grad()\n",
    "\n",
    "   # 予測値の計算\n",
    "   y_pred = net(x)\n",
    "\n",
    "   # 損失関数の計算\n",
    "   loss = loss_fn(y_pred.view_as(y), y)\n",
    "\n",
    "   # 微分の計算\n",
    "   loss.backward()\n",
    "\n",
    "   # パラメータの更新\n",
    "   optimizer.step()\n",
    "\n",
    "   # 収束確認のため損失を保持\n",
    "   losses.append(loss.item())\n",
    "\n",
    "\n",
    "# 学習後のパラメータ\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb461a2ed10>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフのプロット\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ④ MNISTをPyTorchで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        # weight init                                                                      \n",
    "        for m in self.layers.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class cnn2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.r1 = nn.ReLU(inplace=True)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.c2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.r2 = nn.ReLU(inplace=True)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.r3 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.r4 = nn.ReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # weight init                                                                      \n",
    "        for m in self.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.m1(self.r1(self.c1(x)))\n",
    "        x = self.m2(self.r2(self.c2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.r3(self.fc1(x))\n",
    "        x = self.r4(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "000 epoch, 00000, loss=0.37773\n",
      "000 epoch, 00100, loss=0.03834\n",
      "000 epoch, 00200, loss=0.02068\n",
      "000 epoch, 00300, loss=0.00783\n",
      "000 epoch, 00400, loss=0.00720\n",
      "001 epoch, 00000, loss=0.00899\n",
      "001 epoch, 00100, loss=0.00663\n",
      "001 epoch, 00200, loss=0.00293\n",
      "001 epoch, 00300, loss=0.00476\n",
      "001 epoch, 00400, loss=0.01308\n",
      "002 epoch, 00000, loss=0.00414\n",
      "002 epoch, 00100, loss=0.00695\n",
      "002 epoch, 00200, loss=0.00769\n",
      "002 epoch, 00300, loss=0.01498\n",
      "002 epoch, 00400, loss=0.00520\n",
      "test\n",
      "test accuracy = 0.986\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "model = cnn()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# datasetの読み出し                                                                    \n",
    "bs = 128 # batch size                                                                  \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "\n",
    "testset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=bs, shuffle=False)\n",
    "\n",
    "# training                                                                             \n",
    "print('train')\n",
    "model = model.train()\n",
    "for iepoch in range(3):\n",
    "    for iiter, (x, y) in enumerate(trainloader, 0):\n",
    "\n",
    "        y = torch.eye(10)[y]\n",
    "\n",
    "        # 推定                                                                         \n",
    "        y_ = model.forward(x) # y_.shape = (bs, 84)                                    \n",
    "\n",
    "        # loss: cross-entropy                                                          \n",
    "        eps = 1e-7\n",
    "        loss = -torch.mean(y*torch.log(y_+eps))\n",
    "\n",
    "        opt.zero_grad() # 勾配初期化\n",
    "        loss.backward() # backward (勾配計算)\n",
    "        opt.step() # パラメータの微小移動\n",
    "\n",
    "        # 100回に1回進捗を表示（なくてもよい）\n",
    "        if iiter%100==0:\n",
    "            print('%03d epoch, %05d, loss=%.5f' %\n",
    "                  (iepoch, iiter, loss.item()))\n",
    "\n",
    "# test                                                                                 \n",
    "print('test')\n",
    "total, tp = 0, 0\n",
    "model = model.eval()\n",
    "for (x, label) in testloader:\n",
    "\n",
    "    # 推定                                                                             \n",
    "    y_ = model.forward(x)\n",
    "    label_ = y_.argmax(1)\n",
    "\n",
    "    # 結果集計                                                                         \n",
    "    total += label.shape[0]\n",
    "    tp += (label_==label).sum().item()\n",
    "\n",
    "acc = tp/total\n",
    "print('test accuracy = %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】（アドバンス課題）フレームワークの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。  \n",
    "《視点例》  \n",
    "計算速度  \n",
    "コードの行数・可読性  \n",
    "用意されている機能  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 計算速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算速度は以下の通り\n",
    "① PyTorch\n",
    "② tensorflow\n",
    "③ keras\n",
    "「PyTorch」が「tensorflow（keras）」よりも処理速度が速い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② コードの行数・可読性 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「PyTorch」と「tensorflow」は複雑なコードが書ける反面、コードの記載方法が冗長となり可読性は下がる。\n",
    "一方、「keras」はシンプルにコードを書くことができるため可読性が良いが、「tensorflow」のような複雑な処理をコード化するのは難しい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ③ 用意されている機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflowを利用できるプログラミング言語は、PythonやC++、Java、Go\n",
    "\n",
    "\n",
    "KerasはPythonのみ\n",
    "\n",
    "\n",
    "\n",
    "PyTorchを利用できるプログラミング言語は、Pythonのみ\n",
    "Define by runを採用\n",
    "TensorはNumPyのndarrayと同様に使用できる多次元配列であり、GPUでの計算もサポートしていて大規模な行列の計算などに威力を発揮します。\n",
    "\n",
    "　Tensorは自動で微分を計算することができ、ニューラルネットワークの最適化で重要になります。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
